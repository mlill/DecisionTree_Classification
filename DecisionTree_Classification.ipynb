{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Descriptors, Crippen, AllChem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some Warnings informing about future scipy changes.\n",
    "\n",
    "We will suppress them here as they have no influence on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data\n",
    "\n",
    "Here we use classification data on blood brain barrier (BBB) penetration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_table('B3DB_classification.tsv',sep='\\t')\n",
    "\n",
    "table = tmp.loc[:,('compound_name', 'IUPAC_name', 'SMILES', 'BBB+/BBB-')]\n",
    "table = table.dropna(subset=\"BBB+/BBB-\")\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "table.loc[:,'BBB_class'] = 0\n",
    "table.loc[table['BBB+/BBB-'] == 'BBB+', 'BBB_class'] = 1\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molecular descriptors calculation\n",
    "\n",
    "We can use RDKIT to calculate several molecular descriptors (2D and 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will calculate the descriptors and add them to our table\n",
    "for i in table.index:\n",
    "    mol=Chem.MolFromSmiles(table.loc[i,'SMILES'])\n",
    "    table.loc[i,'MolWt']=Descriptors.ExactMolWt (mol)\n",
    "    table.loc[i,'TPSA']=Chem.rdMolDescriptors.CalcTPSA(mol) #Topological Polar Surface Area\n",
    "    table.loc[i,'nRotB']=Descriptors.NumRotatableBonds (mol) #Number of rotable bonds\n",
    "    table.loc[i,'HBD']=Descriptors.NumHDonors(mol) #Number of H bond donors\n",
    "    table.loc[i,'HBA']=Descriptors.NumHAcceptors(mol) #Number of H bond acceptors\n",
    "    table.loc[i,'LogP']=Descriptors.MolLogP(mol) #LogP\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: We will use decision tree classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate x (descriptors) and y (BBB_class) vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_selected = ['MolWt', 'TPSA', 'HBD', 'HBA', 'LogP']\n",
    "\n",
    "x = table.loc[:, descriptors_selected].values\n",
    "y = table.loc[:, ['BBB_class']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test set\n",
    "\n",
    "Here, we use random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform regression tree classification using maximum depth of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"maximum depth: {} nn score: {} \".format(3, clf.score(x_valid,y_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "import pydotplus\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO ## for Python 2\n",
    "except ImportError:\n",
    "    from io import StringIO ## for Python 3\n",
    "\n",
    "\n",
    "dt_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dt_data, \n",
    "                                feature_names=descriptors_selected,  \n",
    "                                class_names=['BBB-', 'BBB+'],  \n",
    "                                filled=True, rounded=True,  \n",
    "                                special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dt_data.getvalue())  \n",
    "graph.write_png('my_decision_tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dependency on max_depth\n",
    "score_list = []\n",
    "for maxd in range(1,25):\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=maxd)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    score_list.append(clf.score(x_valid,y_valid))\n",
    "    \n",
    "plt.plot(range(1,25),score_list)\n",
    "plt.xlabel(\"k values\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the best max_depth value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn model\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=20)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "prediction = clf.predict(x_test)\n",
    "print(\" {} nn score: {} \".format(3,clf.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% confusion matrix\n",
    "y_pred = clf.predict(x_test)\n",
    "y_true = y_test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "# %% cm visualization\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize =(5,5))\n",
    "sns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shallow_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b27a49d05b1edc481c11a586dad53c11bdcb63128eeca144f8ebcf35b86ec5ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
